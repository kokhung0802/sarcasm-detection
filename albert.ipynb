{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "f7Tjl8iyi9qd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AlbertTokenizer, TFAlbertModel, TFAlbertForSequenceClassification\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "C-Z3JYJ0kqmm"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "awzkiti_kzfg",
    "outputId": "058ef10c-49c6-4846-d9ec-05569de77f11"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>olympic torch used to ignite tibetan protesters</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this 594-foot-high basketball shot 'for mankin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dr. oz, mel gibson, &amp; congress called out usin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>excited juror feels like murder trial being pu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>man has mixed feelings about $39 flight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0    olympic torch used to ignite tibetan protesters             1\n",
       "1  this 594-foot-high basketball shot 'for mankin...             0\n",
       "2  dr. oz, mel gibson, & congress called out usin...             0\n",
       "3  excited juror feels like murder trial being pu...             1\n",
       "4            man has mixed feelings about $39 flight             1"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N4qnilPfk0LU",
    "outputId": "fe3a8bca-b36c-4600-9f2e-85b3d2e471cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24038, 2)"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Khx8ihbOlFqV"
   },
   "source": [
    "## **Tokenize Inputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "0u-J0a5ClDYE"
   },
   "outputs": [],
   "source": [
    "albert_name = 'albert-base-v2'\n",
    "tokenizer = AlbertTokenizer.from_pretrained(albert_name,\n",
    "    add_special_tokens=True,\n",
    "    do_lower_case=False,\n",
    "    max_length=80,\n",
    "    pad_to_max_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "mCbg1bJolXjs"
   },
   "outputs": [],
   "source": [
    "def albert_encoder(review):\n",
    "    encoded = tokenizer.encode_plus(review, add_special_tokens=True,\n",
    "        max_length=80,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=True)\n",
    "    return encoded['input_ids'], encoded['token_type_ids'], encoded['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9xWjYIhqlYDb",
    "outputId": "31b6943d-c299-41f3-e1bc-38433f886445"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "albert_train = [albert_encoder(df.iloc[i, 0]) for i in range(df.shape[0])]\n",
    "albert_train = np.array(albert_train)\n",
    "\n",
    "albert_label = df['is_sarcastic'].to_list()\n",
    "albert_label = np.array(albert_label)\n",
    "albert_label = to_categorical(albert_label, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-v15c4Xn4DT",
    "outputId": "abca5461-74e5-4b30-bd9d-72c3daeef43e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21634, 3, 80) (21634, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(albert_train,\n",
    "    albert_label,\n",
    "    test_size=0.1,\n",
    "    random_state=42)\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SnnvoE3Wn99f",
    "outputId": "b4b15f00-e055-41ef-ae2b-87ec5e2e49fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21634, 1, 80)\n"
     ]
    }
   ],
   "source": [
    "tr_reviews, tr_segments, tr_masks = np.split(x_train, 3, axis=1)\n",
    "val_reviews, val_segments, val_masks = np.split(x_val, 3, axis=1)\n",
    "print(tr_reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TaMtm7GLoI14",
    "outputId": "25b076b6-1fcd-49c2-f7e9-3a30e8ac498b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21634, 80)\n"
     ]
    }
   ],
   "source": [
    "tr_reviews = tr_reviews.squeeze()\n",
    "tr_segments = tr_segments.squeeze()\n",
    "tr_masks = tr_masks.squeeze()\n",
    "\n",
    "val_reviews = val_reviews.squeeze()\n",
    "val_segments = val_segments.squeeze()\n",
    "val_masks = val_masks.squeeze()\n",
    "\n",
    "print(tr_reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "vEnbQbx8oOSJ"
   },
   "outputs": [],
   "source": [
    "def example_to_features(input_ids,attention_masks,token_type_ids,y):\n",
    "    return {\"input_ids\": input_ids,\"attention_mask\": attention_masks,\"token_type_ids\": token_type_ids},y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "vNdAAQkNoRFI"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((tr_reviews, tr_masks, tr_segments, y_train)).map(example_to_features).shuffle(100).batch(8)\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((val_reviews,val_masks, val_segments, y_val)).map(example_to_features).shuffle(100).batch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Na5eq-ToYZd"
   },
   "source": [
    "## **Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TvoZDrU0qiO6",
    "outputId": "2944afd9-7c35-489f-9043-7bef95f0131d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFAlbertForSequenceClassification.\n",
      "\n",
      "Some layers of TFAlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "albert_model_2 = TFAlbertForSequenceClassification.from_pretrained(albert_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "5kd1yGk0xObA"
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=2e-5)\n",
    "loss = BinaryCrossentropy(from_logits=True)\n",
    "albert_model_2.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yqto3CTpxY9W",
    "outputId": "6b8e647e-2f63-4a3b-dfc0-491c75caaea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_albert_for_sequence_classification_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "albert (TFAlbertMainLayer)   multiple                  11683584  \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  1538      \n",
      "=================================================================\n",
      "Total params: 11,685,122\n",
      "Trainable params: 11,685,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "albert_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "akoeump-xcIo",
    "outputId": "443ac747-590e-490a-d397-085798efa2a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning ALBERT\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "2705/2705 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.8252WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "2705/2705 [==============================] - 396s 142ms/step - loss: 0.3855 - accuracy: 0.8252 - val_loss: 0.2812 - val_accuracy: 0.8848\n",
      "Epoch 2/3\n",
      "2705/2705 [==============================] - 382s 141ms/step - loss: 0.1964 - accuracy: 0.9231 - val_loss: 0.2443 - val_accuracy: 0.9006\n",
      "Epoch 3/3\n",
      "2705/2705 [==============================] - 382s 141ms/step - loss: 0.1211 - accuracy: 0.9585 - val_loss: 0.3074 - val_accuracy: 0.8927\n"
     ]
    }
   ],
   "source": [
    "print(\"Fine-tuning ALBERT\")\n",
    "albert_history = albert_model_2.fit(train_ds, epochs=3, validation_data=valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAlDzxk2D682"
   },
   "source": [
    "## **Evaluate on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "QbU0DyDKEM54"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/content/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zm-Yta4wETIF",
    "outputId": "217293ff-b654-46d5-ffaa-54206f1d3829"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2671, 2)"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IDMDrfcEEmQ0",
    "outputId": "46bf70c4-07b0-4d5a-a170-78530607ef5a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "X_test = [albert_encoder(test_df.iloc[i, 0]) for i in range(test_df.shape[0])]\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "y_test = test_df['is_sarcastic'].to_list()\n",
    "y_test = np.array(y_test)\n",
    "y_test = to_categorical(y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DXoo0spMFDYL",
    "outputId": "f9c08e98-bfc2-489f-ac4d-2b80081ee24d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2671, 1, 80)\n"
     ]
    }
   ],
   "source": [
    "ts_reviews, ts_segments, ts_masks = np.split(X_test, 3, axis=1)\n",
    "print(ts_reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HZdNVM2oFjH9",
    "outputId": "4164674b-9bab-4b9f-f813-85c1c8aeb8aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2671, 80)\n"
     ]
    }
   ],
   "source": [
    "ts_reviews = ts_reviews.squeeze()\n",
    "ts_segments = ts_segments.squeeze()\n",
    "ts_masks = ts_masks.squeeze()\n",
    "\n",
    "print(ts_reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "08HPGCgEFuXZ"
   },
   "outputs": [],
   "source": [
    "test_ds = tf.data.Dataset.from_tensor_slices((ts_reviews, ts_masks, ts_segments, y_test)).map(example_to_features).shuffle(100).batch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iioHkcw8xywe",
    "outputId": "c4fa2462-fc56-4d62-eb72-b0d10b4e8694"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/334 [==============================] - 19s 56ms/step - loss: 0.2967 - accuracy: 0.8911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2967062294483185, 0.8910520672798157]"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "albert_model_2.evaluate(test_ds)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "FineTuning ALBERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
